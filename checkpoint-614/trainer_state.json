{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 614,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016306563391765185,
      "grad_norm": 0.609375,
      "learning_rate": 0.0001,
      "loss": 1.6162,
      "step": 1
    },
    {
      "epoch": 0.003261312678353037,
      "grad_norm": 0.578125,
      "learning_rate": 0.0001,
      "loss": 1.6006,
      "step": 2
    },
    {
      "epoch": 0.004891969017529555,
      "grad_norm": 0.5703125,
      "learning_rate": 0.0001,
      "loss": 1.585,
      "step": 3
    },
    {
      "epoch": 0.006522625356706074,
      "grad_norm": 1.21875,
      "learning_rate": 0.0001,
      "loss": 1.5537,
      "step": 4
    },
    {
      "epoch": 0.008153281695882593,
      "grad_norm": 5.4375,
      "learning_rate": 0.0001,
      "loss": 1.625,
      "step": 5
    },
    {
      "epoch": 0.00978393803505911,
      "grad_norm": 1.6875,
      "learning_rate": 0.0001,
      "loss": 1.5234,
      "step": 6
    },
    {
      "epoch": 0.01141459437423563,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.5303,
      "step": 7
    },
    {
      "epoch": 0.013045250713412148,
      "grad_norm": 1.0390625,
      "learning_rate": 0.0001,
      "loss": 1.5381,
      "step": 8
    },
    {
      "epoch": 0.014675907052588666,
      "grad_norm": 1.6015625,
      "learning_rate": 0.0001,
      "loss": 1.4863,
      "step": 9
    },
    {
      "epoch": 0.016306563391765186,
      "grad_norm": 1.3046875,
      "learning_rate": 0.0001,
      "loss": 1.5137,
      "step": 10
    },
    {
      "epoch": 0.017937219730941704,
      "grad_norm": 0.984375,
      "learning_rate": 0.0001,
      "loss": 1.4541,
      "step": 11
    },
    {
      "epoch": 0.01956787607011822,
      "grad_norm": 1.4765625,
      "learning_rate": 0.0001,
      "loss": 1.5371,
      "step": 12
    },
    {
      "epoch": 0.02119853240929474,
      "grad_norm": 1.515625,
      "learning_rate": 0.0001,
      "loss": 1.5391,
      "step": 13
    },
    {
      "epoch": 0.02282918874847126,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.502,
      "step": 14
    },
    {
      "epoch": 0.02445984508764778,
      "grad_norm": 0.7109375,
      "learning_rate": 0.0001,
      "loss": 1.5352,
      "step": 15
    },
    {
      "epoch": 0.026090501426824297,
      "grad_norm": 1.1953125,
      "learning_rate": 0.0001,
      "loss": 1.5215,
      "step": 16
    },
    {
      "epoch": 0.027721157766000815,
      "grad_norm": 0.8515625,
      "learning_rate": 0.0001,
      "loss": 1.5029,
      "step": 17
    },
    {
      "epoch": 0.029351814105177332,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.4707,
      "step": 18
    },
    {
      "epoch": 0.030982470444353854,
      "grad_norm": 0.9296875,
      "learning_rate": 0.0001,
      "loss": 1.4658,
      "step": 19
    },
    {
      "epoch": 0.03261312678353037,
      "grad_norm": 2.1875,
      "learning_rate": 0.0001,
      "loss": 1.5088,
      "step": 20
    },
    {
      "epoch": 0.034243783122706886,
      "grad_norm": 1.4453125,
      "learning_rate": 0.0001,
      "loss": 1.4648,
      "step": 21
    },
    {
      "epoch": 0.03587443946188341,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.4365,
      "step": 22
    },
    {
      "epoch": 0.03750509580105993,
      "grad_norm": 1.0546875,
      "learning_rate": 0.0001,
      "loss": 1.4482,
      "step": 23
    },
    {
      "epoch": 0.03913575214023644,
      "grad_norm": 1.3359375,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 24
    },
    {
      "epoch": 0.040766408479412965,
      "grad_norm": 1.328125,
      "learning_rate": 0.0001,
      "loss": 1.3906,
      "step": 25
    },
    {
      "epoch": 0.04239706481858948,
      "grad_norm": 2.28125,
      "learning_rate": 0.0001,
      "loss": 1.46,
      "step": 26
    },
    {
      "epoch": 0.044027721157766,
      "grad_norm": 4.15625,
      "learning_rate": 0.0001,
      "loss": 1.4961,
      "step": 27
    },
    {
      "epoch": 0.04565837749694252,
      "grad_norm": 1.4453125,
      "learning_rate": 0.0001,
      "loss": 1.4316,
      "step": 28
    },
    {
      "epoch": 0.047289033836119036,
      "grad_norm": 1.40625,
      "learning_rate": 0.0001,
      "loss": 1.4492,
      "step": 29
    },
    {
      "epoch": 0.04891969017529556,
      "grad_norm": 1.2109375,
      "learning_rate": 0.0001,
      "loss": 1.4482,
      "step": 30
    },
    {
      "epoch": 0.05055034651447207,
      "grad_norm": 1.046875,
      "learning_rate": 0.0001,
      "loss": 1.4619,
      "step": 31
    },
    {
      "epoch": 0.05218100285364859,
      "grad_norm": 1.234375,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 32
    },
    {
      "epoch": 0.053811659192825115,
      "grad_norm": 1.125,
      "learning_rate": 0.0001,
      "loss": 1.4473,
      "step": 33
    },
    {
      "epoch": 0.05544231553200163,
      "grad_norm": 1.171875,
      "learning_rate": 0.0001,
      "loss": 1.4922,
      "step": 34
    },
    {
      "epoch": 0.05707297187117815,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.4639,
      "step": 35
    },
    {
      "epoch": 0.058703628210354665,
      "grad_norm": 1.1328125,
      "learning_rate": 0.0001,
      "loss": 1.4795,
      "step": 36
    },
    {
      "epoch": 0.060334284549531186,
      "grad_norm": 0.97265625,
      "learning_rate": 0.0001,
      "loss": 1.4268,
      "step": 37
    },
    {
      "epoch": 0.06196494088870771,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.5107,
      "step": 38
    },
    {
      "epoch": 0.06359559722788423,
      "grad_norm": 0.8515625,
      "learning_rate": 0.0001,
      "loss": 1.4482,
      "step": 39
    },
    {
      "epoch": 0.06522625356706074,
      "grad_norm": 0.89453125,
      "learning_rate": 0.0001,
      "loss": 1.4365,
      "step": 40
    },
    {
      "epoch": 0.06685690990623726,
      "grad_norm": 1.140625,
      "learning_rate": 0.0001,
      "loss": 1.3867,
      "step": 41
    },
    {
      "epoch": 0.06848756624541377,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.4326,
      "step": 42
    },
    {
      "epoch": 0.0701182225845903,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.4297,
      "step": 43
    },
    {
      "epoch": 0.07174887892376682,
      "grad_norm": 1.28125,
      "learning_rate": 0.0001,
      "loss": 1.4502,
      "step": 44
    },
    {
      "epoch": 0.07337953526294333,
      "grad_norm": 1.796875,
      "learning_rate": 0.0001,
      "loss": 1.4961,
      "step": 45
    },
    {
      "epoch": 0.07501019160211986,
      "grad_norm": 1.0,
      "learning_rate": 0.0001,
      "loss": 1.3857,
      "step": 46
    },
    {
      "epoch": 0.07664084794129637,
      "grad_norm": 1.34375,
      "learning_rate": 0.0001,
      "loss": 1.4473,
      "step": 47
    },
    {
      "epoch": 0.07827150428047289,
      "grad_norm": 0.9453125,
      "learning_rate": 0.0001,
      "loss": 1.4355,
      "step": 48
    },
    {
      "epoch": 0.07990216061964941,
      "grad_norm": 0.91015625,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 49
    },
    {
      "epoch": 0.08153281695882593,
      "grad_norm": 0.81640625,
      "learning_rate": 0.0001,
      "loss": 1.4736,
      "step": 50
    },
    {
      "epoch": 0.08316347329800244,
      "grad_norm": 1.171875,
      "learning_rate": 0.0001,
      "loss": 1.4014,
      "step": 51
    },
    {
      "epoch": 0.08479412963717896,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.4121,
      "step": 52
    },
    {
      "epoch": 0.08642478597635549,
      "grad_norm": 0.984375,
      "learning_rate": 0.0001,
      "loss": 1.4395,
      "step": 53
    },
    {
      "epoch": 0.088055442315532,
      "grad_norm": 0.91015625,
      "learning_rate": 0.0001,
      "loss": 1.4404,
      "step": 54
    },
    {
      "epoch": 0.08968609865470852,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.4463,
      "step": 55
    },
    {
      "epoch": 0.09131675499388504,
      "grad_norm": 0.95703125,
      "learning_rate": 0.0001,
      "loss": 1.4453,
      "step": 56
    },
    {
      "epoch": 0.09294741133306156,
      "grad_norm": 1.21875,
      "learning_rate": 0.0001,
      "loss": 1.417,
      "step": 57
    },
    {
      "epoch": 0.09457806767223807,
      "grad_norm": 1.2421875,
      "learning_rate": 0.0001,
      "loss": 1.5059,
      "step": 58
    },
    {
      "epoch": 0.0962087240114146,
      "grad_norm": 0.91015625,
      "learning_rate": 0.0001,
      "loss": 1.4502,
      "step": 59
    },
    {
      "epoch": 0.09783938035059112,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.4492,
      "step": 60
    },
    {
      "epoch": 0.09947003668976763,
      "grad_norm": 0.984375,
      "learning_rate": 0.0001,
      "loss": 1.459,
      "step": 61
    },
    {
      "epoch": 0.10110069302894414,
      "grad_norm": 1.140625,
      "learning_rate": 0.0001,
      "loss": 1.4209,
      "step": 62
    },
    {
      "epoch": 0.10273134936812067,
      "grad_norm": 1.1171875,
      "learning_rate": 0.0001,
      "loss": 1.4072,
      "step": 63
    },
    {
      "epoch": 0.10436200570729719,
      "grad_norm": 1.125,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 64
    },
    {
      "epoch": 0.1059926620464737,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.4346,
      "step": 65
    },
    {
      "epoch": 0.10762331838565023,
      "grad_norm": 1.4296875,
      "learning_rate": 0.0001,
      "loss": 1.4639,
      "step": 66
    },
    {
      "epoch": 0.10925397472482674,
      "grad_norm": 1.203125,
      "learning_rate": 0.0001,
      "loss": 1.4277,
      "step": 67
    },
    {
      "epoch": 0.11088463106400326,
      "grad_norm": 1.203125,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 68
    },
    {
      "epoch": 0.11251528740317979,
      "grad_norm": 1.3828125,
      "learning_rate": 0.0001,
      "loss": 1.4268,
      "step": 69
    },
    {
      "epoch": 0.1141459437423563,
      "grad_norm": 1.1484375,
      "learning_rate": 0.0001,
      "loss": 1.3896,
      "step": 70
    },
    {
      "epoch": 0.11577660008153282,
      "grad_norm": 1.1640625,
      "learning_rate": 0.0001,
      "loss": 1.4404,
      "step": 71
    },
    {
      "epoch": 0.11740725642070933,
      "grad_norm": 1.2109375,
      "learning_rate": 0.0001,
      "loss": 1.4238,
      "step": 72
    },
    {
      "epoch": 0.11903791275988586,
      "grad_norm": 1.21875,
      "learning_rate": 0.0001,
      "loss": 1.3564,
      "step": 73
    },
    {
      "epoch": 0.12066856909906237,
      "grad_norm": 1.109375,
      "learning_rate": 0.0001,
      "loss": 1.4141,
      "step": 74
    },
    {
      "epoch": 0.12229922543823889,
      "grad_norm": 1.0390625,
      "learning_rate": 0.0001,
      "loss": 1.3887,
      "step": 75
    },
    {
      "epoch": 0.12392988177741542,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.4346,
      "step": 76
    },
    {
      "epoch": 0.12556053811659193,
      "grad_norm": 1.1640625,
      "learning_rate": 0.0001,
      "loss": 1.4707,
      "step": 77
    },
    {
      "epoch": 0.12719119445576846,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 78
    },
    {
      "epoch": 0.12882185079494496,
      "grad_norm": 1.265625,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 79
    },
    {
      "epoch": 0.1304525071341215,
      "grad_norm": 1.2890625,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 80
    },
    {
      "epoch": 0.13208316347329802,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.3955,
      "step": 81
    },
    {
      "epoch": 0.13371381981247452,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.4424,
      "step": 82
    },
    {
      "epoch": 0.13534447615165104,
      "grad_norm": 1.296875,
      "learning_rate": 0.0001,
      "loss": 1.4287,
      "step": 83
    },
    {
      "epoch": 0.13697513249082754,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.4336,
      "step": 84
    },
    {
      "epoch": 0.13860578883000407,
      "grad_norm": 0.98828125,
      "learning_rate": 0.0001,
      "loss": 1.4229,
      "step": 85
    },
    {
      "epoch": 0.1402364451691806,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3809,
      "step": 86
    },
    {
      "epoch": 0.1418671015083571,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.4375,
      "step": 87
    },
    {
      "epoch": 0.14349775784753363,
      "grad_norm": 0.98828125,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 88
    },
    {
      "epoch": 0.14512841418671016,
      "grad_norm": 1.0859375,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 89
    },
    {
      "epoch": 0.14675907052588666,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 90
    },
    {
      "epoch": 0.1483897268650632,
      "grad_norm": 1.2265625,
      "learning_rate": 0.0001,
      "loss": 1.4561,
      "step": 91
    },
    {
      "epoch": 0.15002038320423972,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.377,
      "step": 92
    },
    {
      "epoch": 0.15165103954341622,
      "grad_norm": 1.2265625,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 93
    },
    {
      "epoch": 0.15328169588259274,
      "grad_norm": 1.359375,
      "learning_rate": 0.0001,
      "loss": 1.4258,
      "step": 94
    },
    {
      "epoch": 0.15491235222176927,
      "grad_norm": 1.46875,
      "learning_rate": 0.0001,
      "loss": 1.4268,
      "step": 95
    },
    {
      "epoch": 0.15654300856094577,
      "grad_norm": 1.15625,
      "learning_rate": 0.0001,
      "loss": 1.416,
      "step": 96
    },
    {
      "epoch": 0.1581736649001223,
      "grad_norm": 1.109375,
      "learning_rate": 0.0001,
      "loss": 1.418,
      "step": 97
    },
    {
      "epoch": 0.15980432123929883,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 98
    },
    {
      "epoch": 0.16143497757847533,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 99
    },
    {
      "epoch": 0.16306563391765186,
      "grad_norm": 0.9140625,
      "learning_rate": 0.0001,
      "loss": 1.4014,
      "step": 100
    },
    {
      "epoch": 0.1646962902568284,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.3965,
      "step": 101
    },
    {
      "epoch": 0.1663269465960049,
      "grad_norm": 1.0546875,
      "learning_rate": 0.0001,
      "loss": 1.4023,
      "step": 102
    },
    {
      "epoch": 0.16795760293518142,
      "grad_norm": 1.125,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 103
    },
    {
      "epoch": 0.16958825927435792,
      "grad_norm": 1.2265625,
      "learning_rate": 0.0001,
      "loss": 1.4258,
      "step": 104
    },
    {
      "epoch": 0.17121891561353444,
      "grad_norm": 1.4375,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 105
    },
    {
      "epoch": 0.17284957195271097,
      "grad_norm": 1.0,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 106
    },
    {
      "epoch": 0.17448022829188747,
      "grad_norm": 1.1640625,
      "learning_rate": 0.0001,
      "loss": 1.4141,
      "step": 107
    },
    {
      "epoch": 0.176110884631064,
      "grad_norm": 0.9921875,
      "learning_rate": 0.0001,
      "loss": 1.4297,
      "step": 108
    },
    {
      "epoch": 0.17774154097024053,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 109
    },
    {
      "epoch": 0.17937219730941703,
      "grad_norm": 1.2734375,
      "learning_rate": 0.0001,
      "loss": 1.4053,
      "step": 110
    },
    {
      "epoch": 0.18100285364859356,
      "grad_norm": 1.1796875,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 111
    },
    {
      "epoch": 0.1826335099877701,
      "grad_norm": 1.265625,
      "learning_rate": 0.0001,
      "loss": 1.4072,
      "step": 112
    },
    {
      "epoch": 0.1842641663269466,
      "grad_norm": 1.3515625,
      "learning_rate": 0.0001,
      "loss": 1.4697,
      "step": 113
    },
    {
      "epoch": 0.18589482266612312,
      "grad_norm": 1.40625,
      "learning_rate": 0.0001,
      "loss": 1.4404,
      "step": 114
    },
    {
      "epoch": 0.18752547900529964,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 115
    },
    {
      "epoch": 0.18915613534447615,
      "grad_norm": 1.0859375,
      "learning_rate": 0.0001,
      "loss": 1.416,
      "step": 116
    },
    {
      "epoch": 0.19078679168365267,
      "grad_norm": 1.03125,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 117
    },
    {
      "epoch": 0.1924174480228292,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.3887,
      "step": 118
    },
    {
      "epoch": 0.1940481043620057,
      "grad_norm": 1.265625,
      "learning_rate": 0.0001,
      "loss": 1.4375,
      "step": 119
    },
    {
      "epoch": 0.19567876070118223,
      "grad_norm": 1.15625,
      "learning_rate": 0.0001,
      "loss": 1.416,
      "step": 120
    },
    {
      "epoch": 0.19730941704035873,
      "grad_norm": 0.93359375,
      "learning_rate": 0.0001,
      "loss": 1.4424,
      "step": 121
    },
    {
      "epoch": 0.19894007337953526,
      "grad_norm": 1.1171875,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 122
    },
    {
      "epoch": 0.2005707297187118,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.4053,
      "step": 123
    },
    {
      "epoch": 0.2022013860578883,
      "grad_norm": 0.9140625,
      "learning_rate": 0.0001,
      "loss": 1.4287,
      "step": 124
    },
    {
      "epoch": 0.20383204239706482,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.4072,
      "step": 125
    },
    {
      "epoch": 0.20546269873624134,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.4307,
      "step": 126
    },
    {
      "epoch": 0.20709335507541785,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.3887,
      "step": 127
    },
    {
      "epoch": 0.20872401141459437,
      "grad_norm": 1.046875,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 128
    },
    {
      "epoch": 0.2103546677537709,
      "grad_norm": 1.1953125,
      "learning_rate": 0.0001,
      "loss": 1.4658,
      "step": 129
    },
    {
      "epoch": 0.2119853240929474,
      "grad_norm": 1.1796875,
      "learning_rate": 0.0001,
      "loss": 1.3496,
      "step": 130
    },
    {
      "epoch": 0.21361598043212393,
      "grad_norm": 1.03125,
      "learning_rate": 0.0001,
      "loss": 1.3984,
      "step": 131
    },
    {
      "epoch": 0.21524663677130046,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.3604,
      "step": 132
    },
    {
      "epoch": 0.21687729311047696,
      "grad_norm": 1.1875,
      "learning_rate": 0.0001,
      "loss": 1.3398,
      "step": 133
    },
    {
      "epoch": 0.2185079494496535,
      "grad_norm": 1.421875,
      "learning_rate": 0.0001,
      "loss": 1.3848,
      "step": 134
    },
    {
      "epoch": 0.22013860578883002,
      "grad_norm": 1.515625,
      "learning_rate": 0.0001,
      "loss": 1.3936,
      "step": 135
    },
    {
      "epoch": 0.22176926212800652,
      "grad_norm": 1.1484375,
      "learning_rate": 0.0001,
      "loss": 1.3574,
      "step": 136
    },
    {
      "epoch": 0.22339991846718305,
      "grad_norm": 1.2734375,
      "learning_rate": 0.0001,
      "loss": 1.4229,
      "step": 137
    },
    {
      "epoch": 0.22503057480635957,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 138
    },
    {
      "epoch": 0.22666123114553607,
      "grad_norm": 0.90234375,
      "learning_rate": 0.0001,
      "loss": 1.4209,
      "step": 139
    },
    {
      "epoch": 0.2282918874847126,
      "grad_norm": 0.98828125,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 140
    },
    {
      "epoch": 0.2299225438238891,
      "grad_norm": 1.2109375,
      "learning_rate": 0.0001,
      "loss": 1.3574,
      "step": 141
    },
    {
      "epoch": 0.23155320016306563,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.3711,
      "step": 142
    },
    {
      "epoch": 0.23318385650224216,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.4336,
      "step": 143
    },
    {
      "epoch": 0.23481451284141866,
      "grad_norm": 0.9921875,
      "learning_rate": 0.0001,
      "loss": 1.3799,
      "step": 144
    },
    {
      "epoch": 0.2364451691805952,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.4033,
      "step": 145
    },
    {
      "epoch": 0.23807582551977172,
      "grad_norm": 1.109375,
      "learning_rate": 0.0001,
      "loss": 1.3936,
      "step": 146
    },
    {
      "epoch": 0.23970648185894822,
      "grad_norm": 1.0859375,
      "learning_rate": 0.0001,
      "loss": 1.4453,
      "step": 147
    },
    {
      "epoch": 0.24133713819812475,
      "grad_norm": 0.96875,
      "learning_rate": 0.0001,
      "loss": 1.4072,
      "step": 148
    },
    {
      "epoch": 0.24296779453730127,
      "grad_norm": 1.0546875,
      "learning_rate": 0.0001,
      "loss": 1.4248,
      "step": 149
    },
    {
      "epoch": 0.24459845087647777,
      "grad_norm": 1.2421875,
      "learning_rate": 0.0001,
      "loss": 1.4229,
      "step": 150
    },
    {
      "epoch": 0.2462291072156543,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.4326,
      "step": 151
    },
    {
      "epoch": 0.24785976355483083,
      "grad_norm": 0.91015625,
      "learning_rate": 0.0001,
      "loss": 1.3711,
      "step": 152
    },
    {
      "epoch": 0.24949041989400733,
      "grad_norm": 0.80859375,
      "learning_rate": 0.0001,
      "loss": 1.416,
      "step": 153
    },
    {
      "epoch": 0.25112107623318386,
      "grad_norm": 1.1484375,
      "learning_rate": 0.0001,
      "loss": 1.3477,
      "step": 154
    },
    {
      "epoch": 0.2527517325723604,
      "grad_norm": 0.90234375,
      "learning_rate": 0.0001,
      "loss": 1.377,
      "step": 155
    },
    {
      "epoch": 0.2543823889115369,
      "grad_norm": 0.93359375,
      "learning_rate": 0.0001,
      "loss": 1.4355,
      "step": 156
    },
    {
      "epoch": 0.2560130452507134,
      "grad_norm": 1.0,
      "learning_rate": 0.0001,
      "loss": 1.4053,
      "step": 157
    },
    {
      "epoch": 0.2576437015898899,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.376,
      "step": 158
    },
    {
      "epoch": 0.25927435792906645,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 159
    },
    {
      "epoch": 0.260905014268243,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.3359,
      "step": 160
    },
    {
      "epoch": 0.2625356706074195,
      "grad_norm": 1.1328125,
      "learning_rate": 0.0001,
      "loss": 1.4209,
      "step": 161
    },
    {
      "epoch": 0.26416632694659603,
      "grad_norm": 1.140625,
      "learning_rate": 0.0001,
      "loss": 1.4141,
      "step": 162
    },
    {
      "epoch": 0.2657969832857725,
      "grad_norm": 1.171875,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 163
    },
    {
      "epoch": 0.26742763962494903,
      "grad_norm": 0.984375,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 164
    },
    {
      "epoch": 0.26905829596412556,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3809,
      "step": 165
    },
    {
      "epoch": 0.2706889523033021,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.3984,
      "step": 166
    },
    {
      "epoch": 0.2723196086424786,
      "grad_norm": 0.9609375,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 167
    },
    {
      "epoch": 0.2739502649816551,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.4463,
      "step": 168
    },
    {
      "epoch": 0.2755809213208316,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.3047,
      "step": 169
    },
    {
      "epoch": 0.27721157766000815,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.3906,
      "step": 170
    },
    {
      "epoch": 0.2788422339991847,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.4258,
      "step": 171
    },
    {
      "epoch": 0.2804728903383612,
      "grad_norm": 1.0234375,
      "learning_rate": 0.0001,
      "loss": 1.4336,
      "step": 172
    },
    {
      "epoch": 0.28210354667753773,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 173
    },
    {
      "epoch": 0.2837342030167142,
      "grad_norm": 0.9296875,
      "learning_rate": 0.0001,
      "loss": 1.3691,
      "step": 174
    },
    {
      "epoch": 0.28536485935589073,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.4297,
      "step": 175
    },
    {
      "epoch": 0.28699551569506726,
      "grad_norm": 1.2109375,
      "learning_rate": 0.0001,
      "loss": 1.4463,
      "step": 176
    },
    {
      "epoch": 0.2886261720342438,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.3633,
      "step": 177
    },
    {
      "epoch": 0.2902568283734203,
      "grad_norm": 0.9609375,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 178
    },
    {
      "epoch": 0.29188748471259685,
      "grad_norm": 0.9921875,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 179
    },
    {
      "epoch": 0.2935181410517733,
      "grad_norm": 1.0,
      "learning_rate": 0.0001,
      "loss": 1.3945,
      "step": 180
    },
    {
      "epoch": 0.29514879739094985,
      "grad_norm": 1.1328125,
      "learning_rate": 0.0001,
      "loss": 1.3799,
      "step": 181
    },
    {
      "epoch": 0.2967794537301264,
      "grad_norm": 1.046875,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 182
    },
    {
      "epoch": 0.2984101100693029,
      "grad_norm": 1.2421875,
      "learning_rate": 0.0001,
      "loss": 1.417,
      "step": 183
    },
    {
      "epoch": 0.30004076640847943,
      "grad_norm": 1.2578125,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 184
    },
    {
      "epoch": 0.3016714227476559,
      "grad_norm": 1.046875,
      "learning_rate": 0.0001,
      "loss": 1.3838,
      "step": 185
    },
    {
      "epoch": 0.30330207908683243,
      "grad_norm": 1.1640625,
      "learning_rate": 0.0001,
      "loss": 1.417,
      "step": 186
    },
    {
      "epoch": 0.30493273542600896,
      "grad_norm": 0.93359375,
      "learning_rate": 0.0001,
      "loss": 1.3916,
      "step": 187
    },
    {
      "epoch": 0.3065633917651855,
      "grad_norm": 0.984375,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 188
    },
    {
      "epoch": 0.308194048104362,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 189
    },
    {
      "epoch": 0.30982470444353855,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 190
    },
    {
      "epoch": 0.311455360782715,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.4131,
      "step": 191
    },
    {
      "epoch": 0.31308601712189155,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3643,
      "step": 192
    },
    {
      "epoch": 0.3147166734610681,
      "grad_norm": 1.03125,
      "learning_rate": 0.0001,
      "loss": 1.3506,
      "step": 193
    },
    {
      "epoch": 0.3163473298002446,
      "grad_norm": 0.96484375,
      "learning_rate": 0.0001,
      "loss": 1.3926,
      "step": 194
    },
    {
      "epoch": 0.31797798613942113,
      "grad_norm": 1.2578125,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 195
    },
    {
      "epoch": 0.31960864247859766,
      "grad_norm": 1.1171875,
      "learning_rate": 0.0001,
      "loss": 1.4131,
      "step": 196
    },
    {
      "epoch": 0.32123929881777413,
      "grad_norm": 0.98828125,
      "learning_rate": 0.0001,
      "loss": 1.3789,
      "step": 197
    },
    {
      "epoch": 0.32286995515695066,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 198
    },
    {
      "epoch": 0.3245006114961272,
      "grad_norm": 0.9453125,
      "learning_rate": 0.0001,
      "loss": 1.3984,
      "step": 199
    },
    {
      "epoch": 0.3261312678353037,
      "grad_norm": 1.203125,
      "learning_rate": 0.0001,
      "loss": 1.4355,
      "step": 200
    },
    {
      "epoch": 0.32776192417448025,
      "grad_norm": 0.9140625,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 201
    },
    {
      "epoch": 0.3293925805136568,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.4131,
      "step": 202
    },
    {
      "epoch": 0.33102323685283325,
      "grad_norm": 0.80078125,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 203
    },
    {
      "epoch": 0.3326538931920098,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0001,
      "loss": 1.4346,
      "step": 204
    },
    {
      "epoch": 0.3342845495311863,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.374,
      "step": 205
    },
    {
      "epoch": 0.33591520587036283,
      "grad_norm": 1.03125,
      "learning_rate": 0.0001,
      "loss": 1.3623,
      "step": 206
    },
    {
      "epoch": 0.33754586220953936,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 207
    },
    {
      "epoch": 0.33917651854871583,
      "grad_norm": 0.93359375,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 208
    },
    {
      "epoch": 0.34080717488789236,
      "grad_norm": 0.9140625,
      "learning_rate": 0.0001,
      "loss": 1.3965,
      "step": 209
    },
    {
      "epoch": 0.3424378312270689,
      "grad_norm": 1.125,
      "learning_rate": 0.0001,
      "loss": 1.3896,
      "step": 210
    },
    {
      "epoch": 0.3440684875662454,
      "grad_norm": 0.96875,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 211
    },
    {
      "epoch": 0.34569914390542195,
      "grad_norm": 1.234375,
      "learning_rate": 0.0001,
      "loss": 1.4385,
      "step": 212
    },
    {
      "epoch": 0.3473298002445985,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.3809,
      "step": 213
    },
    {
      "epoch": 0.34896045658377495,
      "grad_norm": 0.87890625,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 214
    },
    {
      "epoch": 0.3505911129229515,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 215
    },
    {
      "epoch": 0.352221769262128,
      "grad_norm": 0.8828125,
      "learning_rate": 0.0001,
      "loss": 1.3965,
      "step": 216
    },
    {
      "epoch": 0.35385242560130453,
      "grad_norm": 0.91796875,
      "learning_rate": 0.0001,
      "loss": 1.3945,
      "step": 217
    },
    {
      "epoch": 0.35548308194048106,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3848,
      "step": 218
    },
    {
      "epoch": 0.3571137382796576,
      "grad_norm": 0.91796875,
      "learning_rate": 0.0001,
      "loss": 1.416,
      "step": 219
    },
    {
      "epoch": 0.35874439461883406,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.4229,
      "step": 220
    },
    {
      "epoch": 0.3603750509580106,
      "grad_norm": 0.9609375,
      "learning_rate": 0.0001,
      "loss": 1.3594,
      "step": 221
    },
    {
      "epoch": 0.3620057072971871,
      "grad_norm": 0.98046875,
      "learning_rate": 0.0001,
      "loss": 1.3613,
      "step": 222
    },
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 223
    },
    {
      "epoch": 0.3652670199755402,
      "grad_norm": 1.296875,
      "learning_rate": 0.0001,
      "loss": 1.292,
      "step": 224
    },
    {
      "epoch": 0.36689767631471665,
      "grad_norm": 1.625,
      "learning_rate": 0.0001,
      "loss": 1.4492,
      "step": 225
    },
    {
      "epoch": 0.3685283326538932,
      "grad_norm": 1.0390625,
      "learning_rate": 0.0001,
      "loss": 1.3252,
      "step": 226
    },
    {
      "epoch": 0.3701589889930697,
      "grad_norm": 2.203125,
      "learning_rate": 0.0001,
      "loss": 1.46,
      "step": 227
    },
    {
      "epoch": 0.37178964533224623,
      "grad_norm": 1.2578125,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 228
    },
    {
      "epoch": 0.37342030167142276,
      "grad_norm": 0.9453125,
      "learning_rate": 0.0001,
      "loss": 1.3652,
      "step": 229
    },
    {
      "epoch": 0.3750509580105993,
      "grad_norm": 0.98046875,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 230
    },
    {
      "epoch": 0.37668161434977576,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 231
    },
    {
      "epoch": 0.3783122706889523,
      "grad_norm": 1.3203125,
      "learning_rate": 0.0001,
      "loss": 1.332,
      "step": 232
    },
    {
      "epoch": 0.3799429270281288,
      "grad_norm": 0.8515625,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 233
    },
    {
      "epoch": 0.38157358336730535,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.4131,
      "step": 234
    },
    {
      "epoch": 0.3832042397064819,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 235
    },
    {
      "epoch": 0.3848348960456584,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 236
    },
    {
      "epoch": 0.3864655523848349,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.3984,
      "step": 237
    },
    {
      "epoch": 0.3880962087240114,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 238
    },
    {
      "epoch": 0.38972686506318793,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.4141,
      "step": 239
    },
    {
      "epoch": 0.39135752140236446,
      "grad_norm": 1.484375,
      "learning_rate": 0.0001,
      "loss": 1.4785,
      "step": 240
    },
    {
      "epoch": 0.392988177741541,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3643,
      "step": 241
    },
    {
      "epoch": 0.39461883408071746,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 242
    },
    {
      "epoch": 0.396249490419894,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 243
    },
    {
      "epoch": 0.3978801467590705,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 244
    },
    {
      "epoch": 0.39951080309824705,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.4463,
      "step": 245
    },
    {
      "epoch": 0.4011414594374236,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.4629,
      "step": 246
    },
    {
      "epoch": 0.4027721157766001,
      "grad_norm": 0.8046875,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 247
    },
    {
      "epoch": 0.4044027721157766,
      "grad_norm": 0.80859375,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 248
    },
    {
      "epoch": 0.4060334284549531,
      "grad_norm": 0.75,
      "learning_rate": 0.0001,
      "loss": 1.418,
      "step": 249
    },
    {
      "epoch": 0.40766408479412963,
      "grad_norm": 0.7734375,
      "learning_rate": 0.0001,
      "loss": 1.3945,
      "step": 250
    },
    {
      "epoch": 0.40929474113330616,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.375,
      "step": 251
    },
    {
      "epoch": 0.4109253974724827,
      "grad_norm": 0.8125,
      "learning_rate": 0.0001,
      "loss": 1.416,
      "step": 252
    },
    {
      "epoch": 0.4125560538116592,
      "grad_norm": 0.80078125,
      "learning_rate": 0.0001,
      "loss": 1.376,
      "step": 253
    },
    {
      "epoch": 0.4141867101508357,
      "grad_norm": 1.0234375,
      "learning_rate": 0.0001,
      "loss": 1.4443,
      "step": 254
    },
    {
      "epoch": 0.4158173664900122,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 255
    },
    {
      "epoch": 0.41744802282918875,
      "grad_norm": 0.859375,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 256
    },
    {
      "epoch": 0.4190786791683653,
      "grad_norm": 0.9140625,
      "learning_rate": 0.0001,
      "loss": 1.377,
      "step": 257
    },
    {
      "epoch": 0.4207093355075418,
      "grad_norm": 0.8515625,
      "learning_rate": 0.0001,
      "loss": 1.415,
      "step": 258
    },
    {
      "epoch": 0.4223399918467183,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.3604,
      "step": 259
    },
    {
      "epoch": 0.4239706481858948,
      "grad_norm": 0.8046875,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 260
    },
    {
      "epoch": 0.42560130452507133,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 261
    },
    {
      "epoch": 0.42723196086424786,
      "grad_norm": 0.89453125,
      "learning_rate": 0.0001,
      "loss": 1.3857,
      "step": 262
    },
    {
      "epoch": 0.4288626172034244,
      "grad_norm": 0.95703125,
      "learning_rate": 0.0001,
      "loss": 1.415,
      "step": 263
    },
    {
      "epoch": 0.4304932735426009,
      "grad_norm": 0.95703125,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 264
    },
    {
      "epoch": 0.4321239298817774,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.376,
      "step": 265
    },
    {
      "epoch": 0.4337545862209539,
      "grad_norm": 0.91796875,
      "learning_rate": 0.0001,
      "loss": 1.3691,
      "step": 266
    },
    {
      "epoch": 0.43538524256013045,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 267
    },
    {
      "epoch": 0.437015898899307,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.375,
      "step": 268
    },
    {
      "epoch": 0.4386465552384835,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 269
    },
    {
      "epoch": 0.44027721157766003,
      "grad_norm": 1.1640625,
      "learning_rate": 0.0001,
      "loss": 1.4385,
      "step": 270
    },
    {
      "epoch": 0.4419078679168365,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.3652,
      "step": 271
    },
    {
      "epoch": 0.44353852425601303,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 272
    },
    {
      "epoch": 0.44516918059518956,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.3789,
      "step": 273
    },
    {
      "epoch": 0.4467998369343661,
      "grad_norm": 0.93359375,
      "learning_rate": 0.0001,
      "loss": 1.3916,
      "step": 274
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 275
    },
    {
      "epoch": 0.45006114961271915,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0001,
      "loss": 1.3652,
      "step": 276
    },
    {
      "epoch": 0.4516918059518956,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.3291,
      "step": 277
    },
    {
      "epoch": 0.45332246229107215,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.3691,
      "step": 278
    },
    {
      "epoch": 0.4549531186302487,
      "grad_norm": 0.96484375,
      "learning_rate": 0.0001,
      "loss": 1.4434,
      "step": 279
    },
    {
      "epoch": 0.4565837749694252,
      "grad_norm": 0.984375,
      "learning_rate": 0.0001,
      "loss": 1.3281,
      "step": 280
    },
    {
      "epoch": 0.45821443130860173,
      "grad_norm": 1.046875,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 281
    },
    {
      "epoch": 0.4598450876477782,
      "grad_norm": 1.125,
      "learning_rate": 0.0001,
      "loss": 1.4023,
      "step": 282
    },
    {
      "epoch": 0.46147574398695473,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.3809,
      "step": 283
    },
    {
      "epoch": 0.46310640032613126,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.3594,
      "step": 284
    },
    {
      "epoch": 0.4647370566653078,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 285
    },
    {
      "epoch": 0.4663677130044843,
      "grad_norm": 1.0546875,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 286
    },
    {
      "epoch": 0.46799836934366085,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.3633,
      "step": 287
    },
    {
      "epoch": 0.4696290256828373,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.3955,
      "step": 288
    },
    {
      "epoch": 0.47125968202201385,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.3584,
      "step": 289
    },
    {
      "epoch": 0.4728903383611904,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.3809,
      "step": 290
    },
    {
      "epoch": 0.4745209947003669,
      "grad_norm": 0.93359375,
      "learning_rate": 0.0001,
      "loss": 1.3633,
      "step": 291
    },
    {
      "epoch": 0.47615165103954343,
      "grad_norm": 0.9453125,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 292
    },
    {
      "epoch": 0.47778230737871996,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 293
    },
    {
      "epoch": 0.47941296371789643,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.3711,
      "step": 294
    },
    {
      "epoch": 0.48104362005707296,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.374,
      "step": 295
    },
    {
      "epoch": 0.4826742763962495,
      "grad_norm": 0.859375,
      "learning_rate": 0.0001,
      "loss": 1.3633,
      "step": 296
    },
    {
      "epoch": 0.484304932735426,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.374,
      "step": 297
    },
    {
      "epoch": 0.48593558907460255,
      "grad_norm": 0.89453125,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 298
    },
    {
      "epoch": 0.487566245413779,
      "grad_norm": 0.91015625,
      "learning_rate": 0.0001,
      "loss": 1.3584,
      "step": 299
    },
    {
      "epoch": 0.48919690175295555,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.3896,
      "step": 300
    },
    {
      "epoch": 0.4908275580921321,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 301
    },
    {
      "epoch": 0.4924582144313086,
      "grad_norm": 0.8828125,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 302
    },
    {
      "epoch": 0.49408887077048513,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3848,
      "step": 303
    },
    {
      "epoch": 0.49571952710966166,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.3906,
      "step": 304
    },
    {
      "epoch": 0.49735018344883813,
      "grad_norm": 0.82421875,
      "learning_rate": 0.0001,
      "loss": 1.3955,
      "step": 305
    },
    {
      "epoch": 0.49898083978801466,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3711,
      "step": 306
    },
    {
      "epoch": 0.5006114961271912,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3838,
      "step": 307
    },
    {
      "epoch": 0.5022421524663677,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.333,
      "step": 308
    },
    {
      "epoch": 0.5038728088055442,
      "grad_norm": 0.91796875,
      "learning_rate": 0.0001,
      "loss": 1.3271,
      "step": 309
    },
    {
      "epoch": 0.5055034651447208,
      "grad_norm": 1.0546875,
      "learning_rate": 0.0001,
      "loss": 1.3984,
      "step": 310
    },
    {
      "epoch": 0.5071341214838972,
      "grad_norm": 1.1484375,
      "learning_rate": 0.0001,
      "loss": 1.3867,
      "step": 311
    },
    {
      "epoch": 0.5087647778230738,
      "grad_norm": 1.125,
      "learning_rate": 0.0001,
      "loss": 1.4141,
      "step": 312
    },
    {
      "epoch": 0.5103954341622503,
      "grad_norm": 1.3671875,
      "learning_rate": 0.0001,
      "loss": 1.4277,
      "step": 313
    },
    {
      "epoch": 0.5120260905014268,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3867,
      "step": 314
    },
    {
      "epoch": 0.5136567468406034,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.373,
      "step": 315
    },
    {
      "epoch": 0.5152874031797798,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.3447,
      "step": 316
    },
    {
      "epoch": 0.5169180595189564,
      "grad_norm": 0.77734375,
      "learning_rate": 0.0001,
      "loss": 1.3535,
      "step": 317
    },
    {
      "epoch": 0.5185487158581329,
      "grad_norm": 0.76953125,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 318
    },
    {
      "epoch": 0.5201793721973094,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 319
    },
    {
      "epoch": 0.521810028536486,
      "grad_norm": 0.97265625,
      "learning_rate": 0.0001,
      "loss": 1.3301,
      "step": 320
    },
    {
      "epoch": 0.5234406848756624,
      "grad_norm": 0.87890625,
      "learning_rate": 0.0001,
      "loss": 1.4023,
      "step": 321
    },
    {
      "epoch": 0.525071341214839,
      "grad_norm": 0.87890625,
      "learning_rate": 0.0001,
      "loss": 1.3438,
      "step": 322
    },
    {
      "epoch": 0.5267019975540155,
      "grad_norm": 0.8984375,
      "learning_rate": 0.0001,
      "loss": 1.3232,
      "step": 323
    },
    {
      "epoch": 0.5283326538931921,
      "grad_norm": 0.98828125,
      "learning_rate": 0.0001,
      "loss": 1.332,
      "step": 324
    },
    {
      "epoch": 0.5299633102323685,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.332,
      "step": 325
    },
    {
      "epoch": 0.531593966571545,
      "grad_norm": 1.125,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 326
    },
    {
      "epoch": 0.5332246229107216,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.3691,
      "step": 327
    },
    {
      "epoch": 0.5348552792498981,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.4023,
      "step": 328
    },
    {
      "epoch": 0.5364859355890746,
      "grad_norm": 0.984375,
      "learning_rate": 0.0001,
      "loss": 1.4336,
      "step": 329
    },
    {
      "epoch": 0.5381165919282511,
      "grad_norm": 0.82421875,
      "learning_rate": 0.0001,
      "loss": 1.3604,
      "step": 330
    },
    {
      "epoch": 0.5397472482674276,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.374,
      "step": 331
    },
    {
      "epoch": 0.5413779046066042,
      "grad_norm": 0.76171875,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 332
    },
    {
      "epoch": 0.5430085609457806,
      "grad_norm": 0.8515625,
      "learning_rate": 0.0001,
      "loss": 1.3887,
      "step": 333
    },
    {
      "epoch": 0.5446392172849572,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.4863,
      "step": 334
    },
    {
      "epoch": 0.5462698736241337,
      "grad_norm": 0.91015625,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 335
    },
    {
      "epoch": 0.5479005299633102,
      "grad_norm": 1.0859375,
      "learning_rate": 0.0001,
      "loss": 1.332,
      "step": 336
    },
    {
      "epoch": 0.5495311863024868,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.4209,
      "step": 337
    },
    {
      "epoch": 0.5511618426416632,
      "grad_norm": 1.03125,
      "learning_rate": 0.0001,
      "loss": 1.4521,
      "step": 338
    },
    {
      "epoch": 0.5527924989808398,
      "grad_norm": 0.91015625,
      "learning_rate": 0.0001,
      "loss": 1.3848,
      "step": 339
    },
    {
      "epoch": 0.5544231553200163,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.3594,
      "step": 340
    },
    {
      "epoch": 0.5560538116591929,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.3643,
      "step": 341
    },
    {
      "epoch": 0.5576844679983693,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.3359,
      "step": 342
    },
    {
      "epoch": 0.5593151243375458,
      "grad_norm": 1.015625,
      "learning_rate": 0.0001,
      "loss": 1.3711,
      "step": 343
    },
    {
      "epoch": 0.5609457806767224,
      "grad_norm": 1.5234375,
      "learning_rate": 0.0001,
      "loss": 1.4307,
      "step": 344
    },
    {
      "epoch": 0.5625764370158989,
      "grad_norm": 1.265625,
      "learning_rate": 0.0001,
      "loss": 1.4355,
      "step": 345
    },
    {
      "epoch": 0.5642070933550755,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3408,
      "step": 346
    },
    {
      "epoch": 0.5658377496942519,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3301,
      "step": 347
    },
    {
      "epoch": 0.5674684060334284,
      "grad_norm": 0.99609375,
      "learning_rate": 0.0001,
      "loss": 1.3672,
      "step": 348
    },
    {
      "epoch": 0.569099062372605,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3955,
      "step": 349
    },
    {
      "epoch": 0.5707297187117815,
      "grad_norm": 1.0546875,
      "learning_rate": 0.0001,
      "loss": 1.4482,
      "step": 350
    },
    {
      "epoch": 0.572360375050958,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.3926,
      "step": 351
    },
    {
      "epoch": 0.5739910313901345,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 352
    },
    {
      "epoch": 0.575621687729311,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0001,
      "loss": 1.3896,
      "step": 353
    },
    {
      "epoch": 0.5772523440684876,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 354
    },
    {
      "epoch": 0.578883000407664,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 355
    },
    {
      "epoch": 0.5805136567468406,
      "grad_norm": 0.89453125,
      "learning_rate": 0.0001,
      "loss": 1.3789,
      "step": 356
    },
    {
      "epoch": 0.5821443130860171,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.4248,
      "step": 357
    },
    {
      "epoch": 0.5837749694251937,
      "grad_norm": 0.83203125,
      "learning_rate": 0.0001,
      "loss": 1.3652,
      "step": 358
    },
    {
      "epoch": 0.5854056257643702,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 359
    },
    {
      "epoch": 0.5870362821035466,
      "grad_norm": 0.93359375,
      "learning_rate": 0.0001,
      "loss": 1.3291,
      "step": 360
    },
    {
      "epoch": 0.5886669384427232,
      "grad_norm": 0.9453125,
      "learning_rate": 0.0001,
      "loss": 1.3496,
      "step": 361
    },
    {
      "epoch": 0.5902975947818997,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.4033,
      "step": 362
    },
    {
      "epoch": 0.5919282511210763,
      "grad_norm": 1.2265625,
      "learning_rate": 0.0001,
      "loss": 1.4365,
      "step": 363
    },
    {
      "epoch": 0.5935589074602527,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 364
    },
    {
      "epoch": 0.5951895637994292,
      "grad_norm": 0.9921875,
      "learning_rate": 0.0001,
      "loss": 1.4473,
      "step": 365
    },
    {
      "epoch": 0.5968202201386058,
      "grad_norm": 0.76171875,
      "learning_rate": 0.0001,
      "loss": 1.4268,
      "step": 366
    },
    {
      "epoch": 0.5984508764777823,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3867,
      "step": 367
    },
    {
      "epoch": 0.6000815328169589,
      "grad_norm": 0.7734375,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 368
    },
    {
      "epoch": 0.6017121891561353,
      "grad_norm": 0.70703125,
      "learning_rate": 0.0001,
      "loss": 1.3926,
      "step": 369
    },
    {
      "epoch": 0.6033428454953118,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3916,
      "step": 370
    },
    {
      "epoch": 0.6049735018344884,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.3896,
      "step": 371
    },
    {
      "epoch": 0.6066041581736649,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.333,
      "step": 372
    },
    {
      "epoch": 0.6082348145128414,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.3633,
      "step": 373
    },
    {
      "epoch": 0.6098654708520179,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.3574,
      "step": 374
    },
    {
      "epoch": 0.6114961271911945,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.3281,
      "step": 375
    },
    {
      "epoch": 0.613126783530371,
      "grad_norm": 1.234375,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 376
    },
    {
      "epoch": 0.6147574398695475,
      "grad_norm": 1.3515625,
      "learning_rate": 0.0001,
      "loss": 1.3906,
      "step": 377
    },
    {
      "epoch": 0.616388096208724,
      "grad_norm": 1.5546875,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 378
    },
    {
      "epoch": 0.6180187525479005,
      "grad_norm": 1.3046875,
      "learning_rate": 0.0001,
      "loss": 1.3936,
      "step": 379
    },
    {
      "epoch": 0.6196494088870771,
      "grad_norm": 0.89453125,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 380
    },
    {
      "epoch": 0.6212800652262536,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.4209,
      "step": 381
    },
    {
      "epoch": 0.62291072156543,
      "grad_norm": 0.7578125,
      "learning_rate": 0.0001,
      "loss": 1.4229,
      "step": 382
    },
    {
      "epoch": 0.6245413779046066,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 383
    },
    {
      "epoch": 0.6261720342437831,
      "grad_norm": 0.7734375,
      "learning_rate": 0.0001,
      "loss": 1.377,
      "step": 384
    },
    {
      "epoch": 0.6278026905829597,
      "grad_norm": 0.7734375,
      "learning_rate": 0.0001,
      "loss": 1.3838,
      "step": 385
    },
    {
      "epoch": 0.6294333469221361,
      "grad_norm": 0.7109375,
      "learning_rate": 0.0001,
      "loss": 1.4512,
      "step": 386
    },
    {
      "epoch": 0.6310640032613127,
      "grad_norm": 0.9609375,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 387
    },
    {
      "epoch": 0.6326946596004892,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.3848,
      "step": 388
    },
    {
      "epoch": 0.6343253159396657,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.3389,
      "step": 389
    },
    {
      "epoch": 0.6359559722788423,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 390
    },
    {
      "epoch": 0.6375866286180187,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.2822,
      "step": 391
    },
    {
      "epoch": 0.6392172849571953,
      "grad_norm": 1.796875,
      "learning_rate": 0.0001,
      "loss": 1.4365,
      "step": 392
    },
    {
      "epoch": 0.6408479412963718,
      "grad_norm": 1.546875,
      "learning_rate": 0.0001,
      "loss": 1.3848,
      "step": 393
    },
    {
      "epoch": 0.6424785976355483,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.334,
      "step": 394
    },
    {
      "epoch": 0.6441092539747248,
      "grad_norm": 1.2578125,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 395
    },
    {
      "epoch": 0.6457399103139013,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.3516,
      "step": 396
    },
    {
      "epoch": 0.6473705666530779,
      "grad_norm": 1.078125,
      "learning_rate": 0.0001,
      "loss": 1.376,
      "step": 397
    },
    {
      "epoch": 0.6490012229922544,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.4111,
      "step": 398
    },
    {
      "epoch": 0.6506318793314309,
      "grad_norm": 0.76171875,
      "learning_rate": 0.0001,
      "loss": 1.3818,
      "step": 399
    },
    {
      "epoch": 0.6522625356706074,
      "grad_norm": 0.7421875,
      "learning_rate": 0.0001,
      "loss": 1.3867,
      "step": 400
    },
    {
      "epoch": 0.6538931920097839,
      "grad_norm": 0.765625,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 401
    },
    {
      "epoch": 0.6555238483489605,
      "grad_norm": 0.80078125,
      "learning_rate": 0.0001,
      "loss": 1.374,
      "step": 402
    },
    {
      "epoch": 0.657154504688137,
      "grad_norm": 0.7890625,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 403
    },
    {
      "epoch": 0.6587851610273135,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 404
    },
    {
      "epoch": 0.66041581736649,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.3818,
      "step": 405
    },
    {
      "epoch": 0.6620464737056665,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 406
    },
    {
      "epoch": 0.6636771300448431,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.4453,
      "step": 407
    },
    {
      "epoch": 0.6653077863840196,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 408
    },
    {
      "epoch": 0.6669384427231961,
      "grad_norm": 0.96875,
      "learning_rate": 0.0001,
      "loss": 1.3936,
      "step": 409
    },
    {
      "epoch": 0.6685690990623726,
      "grad_norm": 0.953125,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 410
    },
    {
      "epoch": 0.6701997554015491,
      "grad_norm": 0.9921875,
      "learning_rate": 0.0001,
      "loss": 1.3848,
      "step": 411
    },
    {
      "epoch": 0.6718304117407257,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.3486,
      "step": 412
    },
    {
      "epoch": 0.6734610680799021,
      "grad_norm": 0.9453125,
      "learning_rate": 0.0001,
      "loss": 1.3604,
      "step": 413
    },
    {
      "epoch": 0.6750917244190787,
      "grad_norm": 0.8984375,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 414
    },
    {
      "epoch": 0.6767223807582552,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 415
    },
    {
      "epoch": 0.6783530370974317,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3525,
      "step": 416
    },
    {
      "epoch": 0.6799836934366082,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 417
    },
    {
      "epoch": 0.6816143497757847,
      "grad_norm": 0.76953125,
      "learning_rate": 0.0001,
      "loss": 1.3613,
      "step": 418
    },
    {
      "epoch": 0.6832450061149613,
      "grad_norm": 0.7890625,
      "learning_rate": 0.0001,
      "loss": 1.415,
      "step": 419
    },
    {
      "epoch": 0.6848756624541378,
      "grad_norm": 0.83203125,
      "learning_rate": 0.0001,
      "loss": 1.377,
      "step": 420
    },
    {
      "epoch": 0.6865063187933144,
      "grad_norm": 0.96875,
      "learning_rate": 0.0001,
      "loss": 1.3584,
      "step": 421
    },
    {
      "epoch": 0.6881369751324908,
      "grad_norm": 0.82421875,
      "learning_rate": 0.0001,
      "loss": 1.4033,
      "step": 422
    },
    {
      "epoch": 0.6897676314716673,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.4355,
      "step": 423
    },
    {
      "epoch": 0.6913982878108439,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.3799,
      "step": 424
    },
    {
      "epoch": 0.6930289441500204,
      "grad_norm": 0.82421875,
      "learning_rate": 0.0001,
      "loss": 1.3789,
      "step": 425
    },
    {
      "epoch": 0.694659600489197,
      "grad_norm": 0.85546875,
      "learning_rate": 0.0001,
      "loss": 1.3584,
      "step": 426
    },
    {
      "epoch": 0.6962902568283734,
      "grad_norm": 0.98046875,
      "learning_rate": 0.0001,
      "loss": 1.4619,
      "step": 427
    },
    {
      "epoch": 0.6979209131675499,
      "grad_norm": 0.81640625,
      "learning_rate": 0.0001,
      "loss": 1.375,
      "step": 428
    },
    {
      "epoch": 0.6995515695067265,
      "grad_norm": 0.9296875,
      "learning_rate": 0.0001,
      "loss": 1.4033,
      "step": 429
    },
    {
      "epoch": 0.701182225845903,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.3545,
      "step": 430
    },
    {
      "epoch": 0.7028128821850795,
      "grad_norm": 0.921875,
      "learning_rate": 0.0001,
      "loss": 1.3379,
      "step": 431
    },
    {
      "epoch": 0.704443538524256,
      "grad_norm": 0.8984375,
      "learning_rate": 0.0001,
      "loss": 1.4346,
      "step": 432
    },
    {
      "epoch": 0.7060741948634325,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 433
    },
    {
      "epoch": 0.7077048512026091,
      "grad_norm": 1.0,
      "learning_rate": 0.0001,
      "loss": 1.4287,
      "step": 434
    },
    {
      "epoch": 0.7093355075417855,
      "grad_norm": 0.83984375,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 435
    },
    {
      "epoch": 0.7109661638809621,
      "grad_norm": 0.82421875,
      "learning_rate": 0.0001,
      "loss": 1.3623,
      "step": 436
    },
    {
      "epoch": 0.7125968202201386,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.3379,
      "step": 437
    },
    {
      "epoch": 0.7142274765593152,
      "grad_norm": 0.96484375,
      "learning_rate": 0.0001,
      "loss": 1.415,
      "step": 438
    },
    {
      "epoch": 0.7158581328984917,
      "grad_norm": 0.8125,
      "learning_rate": 0.0001,
      "loss": 1.3408,
      "step": 439
    },
    {
      "epoch": 0.7174887892376681,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.3447,
      "step": 440
    },
    {
      "epoch": 0.7191194455768447,
      "grad_norm": 0.8046875,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 441
    },
    {
      "epoch": 0.7207501019160212,
      "grad_norm": 0.7890625,
      "learning_rate": 0.0001,
      "loss": 1.3232,
      "step": 442
    },
    {
      "epoch": 0.7223807582551978,
      "grad_norm": 0.8828125,
      "learning_rate": 0.0001,
      "loss": 1.3369,
      "step": 443
    },
    {
      "epoch": 0.7240114145943742,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.3965,
      "step": 444
    },
    {
      "epoch": 0.7256420709335507,
      "grad_norm": 0.96484375,
      "learning_rate": 0.0001,
      "loss": 1.2812,
      "step": 445
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.3359,
      "step": 446
    },
    {
      "epoch": 0.7289033836119038,
      "grad_norm": 1.1171875,
      "learning_rate": 0.0001,
      "loss": 1.3809,
      "step": 447
    },
    {
      "epoch": 0.7305340399510803,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 448
    },
    {
      "epoch": 0.7321646962902568,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.3438,
      "step": 449
    },
    {
      "epoch": 0.7337953526294333,
      "grad_norm": 0.87890625,
      "learning_rate": 0.0001,
      "loss": 1.3174,
      "step": 450
    },
    {
      "epoch": 0.7354260089686099,
      "grad_norm": 0.99609375,
      "learning_rate": 0.0001,
      "loss": 1.292,
      "step": 451
    },
    {
      "epoch": 0.7370566653077864,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.3604,
      "step": 452
    },
    {
      "epoch": 0.7386873216469629,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.3174,
      "step": 453
    },
    {
      "epoch": 0.7403179779861394,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 454
    },
    {
      "epoch": 0.741948634325316,
      "grad_norm": 1.4609375,
      "learning_rate": 0.0001,
      "loss": 1.4766,
      "step": 455
    },
    {
      "epoch": 0.7435792906644925,
      "grad_norm": 1.046875,
      "learning_rate": 0.0001,
      "loss": 1.3799,
      "step": 456
    },
    {
      "epoch": 0.7452099470036689,
      "grad_norm": 1.0859375,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 457
    },
    {
      "epoch": 0.7468406033428455,
      "grad_norm": 0.83203125,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 458
    },
    {
      "epoch": 0.748471259682022,
      "grad_norm": 0.83984375,
      "learning_rate": 0.0001,
      "loss": 1.3613,
      "step": 459
    },
    {
      "epoch": 0.7501019160211986,
      "grad_norm": 0.68359375,
      "learning_rate": 0.0001,
      "loss": 1.3916,
      "step": 460
    },
    {
      "epoch": 0.751732572360375,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.3662,
      "step": 461
    },
    {
      "epoch": 0.7533632286995515,
      "grad_norm": 0.859375,
      "learning_rate": 0.0001,
      "loss": 1.3672,
      "step": 462
    },
    {
      "epoch": 0.7549938850387281,
      "grad_norm": 0.796875,
      "learning_rate": 0.0001,
      "loss": 1.3955,
      "step": 463
    },
    {
      "epoch": 0.7566245413779046,
      "grad_norm": 0.78125,
      "learning_rate": 0.0001,
      "loss": 1.3945,
      "step": 464
    },
    {
      "epoch": 0.7582551977170812,
      "grad_norm": 0.9140625,
      "learning_rate": 0.0001,
      "loss": 1.3428,
      "step": 465
    },
    {
      "epoch": 0.7598858540562576,
      "grad_norm": 0.80078125,
      "learning_rate": 0.0001,
      "loss": 1.3135,
      "step": 466
    },
    {
      "epoch": 0.7615165103954341,
      "grad_norm": 0.9296875,
      "learning_rate": 0.0001,
      "loss": 1.3301,
      "step": 467
    },
    {
      "epoch": 0.7631471667346107,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.334,
      "step": 468
    },
    {
      "epoch": 0.7647778230737872,
      "grad_norm": 1.4453125,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 469
    },
    {
      "epoch": 0.7664084794129638,
      "grad_norm": 1.7265625,
      "learning_rate": 0.0001,
      "loss": 1.4346,
      "step": 470
    },
    {
      "epoch": 0.7680391357521402,
      "grad_norm": 1.2265625,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 471
    },
    {
      "epoch": 0.7696697920913168,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.376,
      "step": 472
    },
    {
      "epoch": 0.7713004484304933,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.3916,
      "step": 473
    },
    {
      "epoch": 0.7729311047696698,
      "grad_norm": 0.734375,
      "learning_rate": 0.0001,
      "loss": 1.3955,
      "step": 474
    },
    {
      "epoch": 0.7745617611088463,
      "grad_norm": 0.70703125,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 475
    },
    {
      "epoch": 0.7761924174480228,
      "grad_norm": 0.75390625,
      "learning_rate": 0.0001,
      "loss": 1.4014,
      "step": 476
    },
    {
      "epoch": 0.7778230737871994,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 477
    },
    {
      "epoch": 0.7794537301263759,
      "grad_norm": 0.7421875,
      "learning_rate": 0.0001,
      "loss": 1.3965,
      "step": 478
    },
    {
      "epoch": 0.7810843864655523,
      "grad_norm": 0.80078125,
      "learning_rate": 0.0001,
      "loss": 1.3916,
      "step": 479
    },
    {
      "epoch": 0.7827150428047289,
      "grad_norm": 0.6640625,
      "learning_rate": 0.0001,
      "loss": 1.4238,
      "step": 480
    },
    {
      "epoch": 0.7843456991439054,
      "grad_norm": 1.4140625,
      "learning_rate": 0.0001,
      "loss": 1.2842,
      "step": 481
    },
    {
      "epoch": 0.785976355483082,
      "grad_norm": 0.7578125,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 482
    },
    {
      "epoch": 0.7876070118222585,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.4326,
      "step": 483
    },
    {
      "epoch": 0.7892376681614349,
      "grad_norm": 1.0625,
      "learning_rate": 0.0001,
      "loss": 1.3945,
      "step": 484
    },
    {
      "epoch": 0.7908683245006115,
      "grad_norm": 1.1015625,
      "learning_rate": 0.0001,
      "loss": 1.4072,
      "step": 485
    },
    {
      "epoch": 0.792498980839788,
      "grad_norm": 1.28125,
      "learning_rate": 0.0001,
      "loss": 1.4512,
      "step": 486
    },
    {
      "epoch": 0.7941296371789646,
      "grad_norm": 0.90234375,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 487
    },
    {
      "epoch": 0.795760293518141,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3223,
      "step": 488
    },
    {
      "epoch": 0.7973909498573176,
      "grad_norm": 0.79296875,
      "learning_rate": 0.0001,
      "loss": 1.3252,
      "step": 489
    },
    {
      "epoch": 0.7990216061964941,
      "grad_norm": 0.80078125,
      "learning_rate": 0.0001,
      "loss": 1.3643,
      "step": 490
    },
    {
      "epoch": 0.8006522625356706,
      "grad_norm": 0.859375,
      "learning_rate": 0.0001,
      "loss": 1.3623,
      "step": 491
    },
    {
      "epoch": 0.8022829188748472,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3369,
      "step": 492
    },
    {
      "epoch": 0.8039135752140236,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.3789,
      "step": 493
    },
    {
      "epoch": 0.8055442315532002,
      "grad_norm": 0.83984375,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 494
    },
    {
      "epoch": 0.8071748878923767,
      "grad_norm": 0.80859375,
      "learning_rate": 0.0001,
      "loss": 1.3438,
      "step": 495
    },
    {
      "epoch": 0.8088055442315532,
      "grad_norm": 0.95703125,
      "learning_rate": 0.0001,
      "loss": 1.3564,
      "step": 496
    },
    {
      "epoch": 0.8104362005707297,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3379,
      "step": 497
    },
    {
      "epoch": 0.8120668569099062,
      "grad_norm": 1.0234375,
      "learning_rate": 0.0001,
      "loss": 1.3613,
      "step": 498
    },
    {
      "epoch": 0.8136975132490828,
      "grad_norm": 0.9140625,
      "learning_rate": 0.0001,
      "loss": 1.3066,
      "step": 499
    },
    {
      "epoch": 0.8153281695882593,
      "grad_norm": 0.8828125,
      "learning_rate": 0.0001,
      "loss": 1.2842,
      "step": 500
    },
    {
      "epoch": 0.8169588259274357,
      "grad_norm": 1.0,
      "learning_rate": 0.0001,
      "loss": 1.3857,
      "step": 501
    },
    {
      "epoch": 0.8185894822666123,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 502
    },
    {
      "epoch": 0.8202201386057888,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3232,
      "step": 503
    },
    {
      "epoch": 0.8218507949449654,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.332,
      "step": 504
    },
    {
      "epoch": 0.8234814512841419,
      "grad_norm": 0.98828125,
      "learning_rate": 0.0001,
      "loss": 1.3721,
      "step": 505
    },
    {
      "epoch": 0.8251121076233184,
      "grad_norm": 0.83984375,
      "learning_rate": 0.0001,
      "loss": 1.3447,
      "step": 506
    },
    {
      "epoch": 0.8267427639624949,
      "grad_norm": 0.96875,
      "learning_rate": 0.0001,
      "loss": 1.3975,
      "step": 507
    },
    {
      "epoch": 0.8283734203016714,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3164,
      "step": 508
    },
    {
      "epoch": 0.830004076640848,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.3682,
      "step": 509
    },
    {
      "epoch": 0.8316347329800244,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3369,
      "step": 510
    },
    {
      "epoch": 0.833265389319201,
      "grad_norm": 0.8828125,
      "learning_rate": 0.0001,
      "loss": 1.3857,
      "step": 511
    },
    {
      "epoch": 0.8348960456583775,
      "grad_norm": 0.78515625,
      "learning_rate": 0.0001,
      "loss": 1.3457,
      "step": 512
    },
    {
      "epoch": 0.836526701997554,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 513
    },
    {
      "epoch": 0.8381573583367306,
      "grad_norm": 0.859375,
      "learning_rate": 0.0001,
      "loss": 1.377,
      "step": 514
    },
    {
      "epoch": 0.839788014675907,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.3857,
      "step": 515
    },
    {
      "epoch": 0.8414186710150836,
      "grad_norm": 1.1328125,
      "learning_rate": 0.0001,
      "loss": 1.4893,
      "step": 516
    },
    {
      "epoch": 0.8430493273542601,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.3691,
      "step": 517
    },
    {
      "epoch": 0.8446799836934366,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 518
    },
    {
      "epoch": 0.8463106400326131,
      "grad_norm": 0.70703125,
      "learning_rate": 0.0001,
      "loss": 1.3887,
      "step": 519
    },
    {
      "epoch": 0.8479412963717896,
      "grad_norm": 0.83984375,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 520
    },
    {
      "epoch": 0.8495719527109662,
      "grad_norm": 0.703125,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 521
    },
    {
      "epoch": 0.8512026090501427,
      "grad_norm": 0.73046875,
      "learning_rate": 0.0001,
      "loss": 1.4404,
      "step": 522
    },
    {
      "epoch": 0.8528332653893193,
      "grad_norm": 0.734375,
      "learning_rate": 0.0001,
      "loss": 1.4043,
      "step": 523
    },
    {
      "epoch": 0.8544639217284957,
      "grad_norm": 0.76953125,
      "learning_rate": 0.0001,
      "loss": 1.376,
      "step": 524
    },
    {
      "epoch": 0.8560945780676722,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3633,
      "step": 525
    },
    {
      "epoch": 0.8577252344068488,
      "grad_norm": 0.96875,
      "learning_rate": 0.0001,
      "loss": 1.3203,
      "step": 526
    },
    {
      "epoch": 0.8593558907460253,
      "grad_norm": 0.80078125,
      "learning_rate": 0.0001,
      "loss": 1.3691,
      "step": 527
    },
    {
      "epoch": 0.8609865470852018,
      "grad_norm": 1.171875,
      "learning_rate": 0.0001,
      "loss": 1.417,
      "step": 528
    },
    {
      "epoch": 0.8626172034243783,
      "grad_norm": 1.09375,
      "learning_rate": 0.0001,
      "loss": 1.3945,
      "step": 529
    },
    {
      "epoch": 0.8642478597635548,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.4082,
      "step": 530
    },
    {
      "epoch": 0.8658785161027314,
      "grad_norm": 0.83984375,
      "learning_rate": 0.0001,
      "loss": 1.332,
      "step": 531
    },
    {
      "epoch": 0.8675091724419078,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.4258,
      "step": 532
    },
    {
      "epoch": 0.8691398287810844,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.416,
      "step": 533
    },
    {
      "epoch": 0.8707704851202609,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.4014,
      "step": 534
    },
    {
      "epoch": 0.8724011414594374,
      "grad_norm": 0.7265625,
      "learning_rate": 0.0001,
      "loss": 1.3789,
      "step": 535
    },
    {
      "epoch": 0.874031797798614,
      "grad_norm": 0.8125,
      "learning_rate": 0.0001,
      "loss": 1.3633,
      "step": 536
    },
    {
      "epoch": 0.8756624541377904,
      "grad_norm": 0.765625,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 537
    },
    {
      "epoch": 0.877293110476967,
      "grad_norm": 0.9453125,
      "learning_rate": 0.0001,
      "loss": 1.3252,
      "step": 538
    },
    {
      "epoch": 0.8789237668161435,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.3604,
      "step": 539
    },
    {
      "epoch": 0.8805544231553201,
      "grad_norm": 0.7734375,
      "learning_rate": 0.0001,
      "loss": 1.3818,
      "step": 540
    },
    {
      "epoch": 0.8821850794944965,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.3164,
      "step": 541
    },
    {
      "epoch": 0.883815735833673,
      "grad_norm": 1.03125,
      "learning_rate": 0.0001,
      "loss": 1.415,
      "step": 542
    },
    {
      "epoch": 0.8854463921728496,
      "grad_norm": 0.9921875,
      "learning_rate": 0.0001,
      "loss": 1.4053,
      "step": 543
    },
    {
      "epoch": 0.8870770485120261,
      "grad_norm": 0.94921875,
      "learning_rate": 0.0001,
      "loss": 1.4053,
      "step": 544
    },
    {
      "epoch": 0.8887077048512027,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.4199,
      "step": 545
    },
    {
      "epoch": 0.8903383611903791,
      "grad_norm": 0.78515625,
      "learning_rate": 0.0001,
      "loss": 1.3301,
      "step": 546
    },
    {
      "epoch": 0.8919690175295556,
      "grad_norm": 0.828125,
      "learning_rate": 0.0001,
      "loss": 1.3584,
      "step": 547
    },
    {
      "epoch": 0.8935996738687322,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.29,
      "step": 548
    },
    {
      "epoch": 0.8952303302079087,
      "grad_norm": 0.8046875,
      "learning_rate": 0.0001,
      "loss": 1.3584,
      "step": 549
    },
    {
      "epoch": 0.8968609865470852,
      "grad_norm": 0.87890625,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 550
    },
    {
      "epoch": 0.8984916428862617,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.2744,
      "step": 551
    },
    {
      "epoch": 0.9001222992254383,
      "grad_norm": 1.03125,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 552
    },
    {
      "epoch": 0.9017529555646148,
      "grad_norm": 0.9765625,
      "learning_rate": 0.0001,
      "loss": 1.2988,
      "step": 553
    },
    {
      "epoch": 0.9033836119037912,
      "grad_norm": 1.0,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 554
    },
    {
      "epoch": 0.9050142682429678,
      "grad_norm": 0.90625,
      "learning_rate": 0.0001,
      "loss": 1.3398,
      "step": 555
    },
    {
      "epoch": 0.9066449245821443,
      "grad_norm": 0.84765625,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 556
    },
    {
      "epoch": 0.9082755809213209,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.4062,
      "step": 557
    },
    {
      "epoch": 0.9099062372604974,
      "grad_norm": 1.0234375,
      "learning_rate": 0.0001,
      "loss": 1.4375,
      "step": 558
    },
    {
      "epoch": 0.9115368935996738,
      "grad_norm": 0.81640625,
      "learning_rate": 0.0001,
      "loss": 1.3867,
      "step": 559
    },
    {
      "epoch": 0.9131675499388504,
      "grad_norm": 0.7734375,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 560
    },
    {
      "epoch": 0.9147982062780269,
      "grad_norm": 0.79296875,
      "learning_rate": 0.0001,
      "loss": 1.3994,
      "step": 561
    },
    {
      "epoch": 0.9164288626172035,
      "grad_norm": 0.78125,
      "learning_rate": 0.0001,
      "loss": 1.335,
      "step": 562
    },
    {
      "epoch": 0.9180595189563799,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 563
    },
    {
      "epoch": 0.9196901752955564,
      "grad_norm": 0.765625,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 564
    },
    {
      "epoch": 0.921320831634733,
      "grad_norm": 0.86328125,
      "learning_rate": 0.0001,
      "loss": 1.3291,
      "step": 565
    },
    {
      "epoch": 0.9229514879739095,
      "grad_norm": 0.78125,
      "learning_rate": 0.0001,
      "loss": 1.3779,
      "step": 566
    },
    {
      "epoch": 0.924582144313086,
      "grad_norm": 0.875,
      "learning_rate": 0.0001,
      "loss": 1.3252,
      "step": 567
    },
    {
      "epoch": 0.9262128006522625,
      "grad_norm": 0.94140625,
      "learning_rate": 0.0001,
      "loss": 1.4365,
      "step": 568
    },
    {
      "epoch": 0.9278434569914391,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3213,
      "step": 569
    },
    {
      "epoch": 0.9294741133306156,
      "grad_norm": 1.171875,
      "learning_rate": 0.0001,
      "loss": 1.4189,
      "step": 570
    },
    {
      "epoch": 0.931104769669792,
      "grad_norm": 1.1640625,
      "learning_rate": 0.0001,
      "loss": 1.4121,
      "step": 571
    },
    {
      "epoch": 0.9327354260089686,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3486,
      "step": 572
    },
    {
      "epoch": 0.9343660823481451,
      "grad_norm": 0.890625,
      "learning_rate": 0.0001,
      "loss": 1.292,
      "step": 573
    },
    {
      "epoch": 0.9359967386873217,
      "grad_norm": 0.83984375,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 574
    },
    {
      "epoch": 0.9376273950264982,
      "grad_norm": 0.80859375,
      "learning_rate": 0.0001,
      "loss": 1.3398,
      "step": 575
    },
    {
      "epoch": 0.9392580513656746,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3877,
      "step": 576
    },
    {
      "epoch": 0.9408887077048512,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0001,
      "loss": 1.3379,
      "step": 577
    },
    {
      "epoch": 0.9425193640440277,
      "grad_norm": 0.77734375,
      "learning_rate": 0.0001,
      "loss": 1.373,
      "step": 578
    },
    {
      "epoch": 0.9441500203832043,
      "grad_norm": 0.7890625,
      "learning_rate": 0.0001,
      "loss": 1.3477,
      "step": 579
    },
    {
      "epoch": 0.9457806767223808,
      "grad_norm": 0.83203125,
      "learning_rate": 0.0001,
      "loss": 1.4004,
      "step": 580
    },
    {
      "epoch": 0.9474113330615572,
      "grad_norm": 0.8125,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 581
    },
    {
      "epoch": 0.9490419894007338,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3154,
      "step": 582
    },
    {
      "epoch": 0.9506726457399103,
      "grad_norm": 1.140625,
      "learning_rate": 0.0001,
      "loss": 1.4336,
      "step": 583
    },
    {
      "epoch": 0.9523033020790869,
      "grad_norm": 0.79296875,
      "learning_rate": 0.0001,
      "loss": 1.3301,
      "step": 584
    },
    {
      "epoch": 0.9539339584182633,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.3652,
      "step": 585
    },
    {
      "epoch": 0.9555646147574399,
      "grad_norm": 0.8984375,
      "learning_rate": 0.0001,
      "loss": 1.4082,
      "step": 586
    },
    {
      "epoch": 0.9571952710966164,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0001,
      "loss": 1.3623,
      "step": 587
    },
    {
      "epoch": 0.9588259274357929,
      "grad_norm": 0.78515625,
      "learning_rate": 0.0001,
      "loss": 1.3477,
      "step": 588
    },
    {
      "epoch": 0.9604565837749695,
      "grad_norm": 0.7578125,
      "learning_rate": 0.0001,
      "loss": 1.3389,
      "step": 589
    },
    {
      "epoch": 0.9620872401141459,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3818,
      "step": 590
    },
    {
      "epoch": 0.9637178964533225,
      "grad_norm": 0.8125,
      "learning_rate": 0.0001,
      "loss": 1.334,
      "step": 591
    },
    {
      "epoch": 0.965348552792499,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.3916,
      "step": 592
    },
    {
      "epoch": 0.9669792091316755,
      "grad_norm": 0.8671875,
      "learning_rate": 0.0001,
      "loss": 1.3701,
      "step": 593
    },
    {
      "epoch": 0.968609865470852,
      "grad_norm": 0.9375,
      "learning_rate": 0.0001,
      "loss": 1.3389,
      "step": 594
    },
    {
      "epoch": 0.9702405218100285,
      "grad_norm": 0.8046875,
      "learning_rate": 0.0001,
      "loss": 1.3594,
      "step": 595
    },
    {
      "epoch": 0.9718711781492051,
      "grad_norm": 0.82421875,
      "learning_rate": 0.0001,
      "loss": 1.3564,
      "step": 596
    },
    {
      "epoch": 0.9735018344883816,
      "grad_norm": 1.0078125,
      "learning_rate": 0.0001,
      "loss": 1.4092,
      "step": 597
    },
    {
      "epoch": 0.975132490827558,
      "grad_norm": 1.1328125,
      "learning_rate": 0.0001,
      "loss": 1.4102,
      "step": 598
    },
    {
      "epoch": 0.9767631471667346,
      "grad_norm": 0.8828125,
      "learning_rate": 0.0001,
      "loss": 1.333,
      "step": 599
    },
    {
      "epoch": 0.9783938035059111,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0001,
      "loss": 1.3594,
      "step": 600
    },
    {
      "epoch": 0.9800244598450877,
      "grad_norm": 0.81640625,
      "learning_rate": 0.0001,
      "loss": 1.3467,
      "step": 601
    },
    {
      "epoch": 0.9816551161842642,
      "grad_norm": 0.76953125,
      "learning_rate": 0.0001,
      "loss": 1.3525,
      "step": 602
    },
    {
      "epoch": 0.9832857725234407,
      "grad_norm": 0.796875,
      "learning_rate": 0.0001,
      "loss": 1.4219,
      "step": 603
    },
    {
      "epoch": 0.9849164288626172,
      "grad_norm": 0.71875,
      "learning_rate": 0.0001,
      "loss": 1.3428,
      "step": 604
    },
    {
      "epoch": 0.9865470852017937,
      "grad_norm": 0.84375,
      "learning_rate": 0.0001,
      "loss": 1.3486,
      "step": 605
    },
    {
      "epoch": 0.9881777415409703,
      "grad_norm": 0.82421875,
      "learning_rate": 0.0001,
      "loss": 1.3828,
      "step": 606
    },
    {
      "epoch": 0.9898083978801467,
      "grad_norm": 0.87109375,
      "learning_rate": 0.0001,
      "loss": 1.3369,
      "step": 607
    },
    {
      "epoch": 0.9914390542193233,
      "grad_norm": 0.87890625,
      "learning_rate": 0.0001,
      "loss": 1.4287,
      "step": 608
    },
    {
      "epoch": 0.9930697105584998,
      "grad_norm": 0.796875,
      "learning_rate": 0.0001,
      "loss": 1.3799,
      "step": 609
    },
    {
      "epoch": 0.9947003668976763,
      "grad_norm": 0.8359375,
      "learning_rate": 0.0001,
      "loss": 1.3555,
      "step": 610
    },
    {
      "epoch": 0.9963310232368529,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0001,
      "loss": 1.2939,
      "step": 611
    },
    {
      "epoch": 0.9979616795760293,
      "grad_norm": 0.9609375,
      "learning_rate": 0.0001,
      "loss": 1.3789,
      "step": 612
    },
    {
      "epoch": 0.9995923359152059,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001,
      "loss": 1.4473,
      "step": 613
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7265625,
      "learning_rate": 0.0001,
      "loss": 0.3389,
      "step": 614
    }
  ],
  "logging_steps": 1,
  "max_steps": 614,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
// Beta
// 0 / 0
// used queries
// 1